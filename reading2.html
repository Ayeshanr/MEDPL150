<h3><em>With ‘AI slop’ distorting our reality, the world is sleepwalking into disaster</em>
    by Nesrine Malik</h3>
</a>
    
    <p class="indent">In “With ‘AI slop’ distorting our reality, the world is sleepwalking into disaster,” Nesrine Malik argues that artificial intelligence is reshaping how we perceive truth by flooding our lives with fabricated yet convincing imagery. She describes two parallel image channels, one with real pictures and footage of the world as it is and the other dominated by AI-generated fantasy, propaganda, and low-quality content. What makes this especially troubling is how seamlessly these streams merge. Malik’s example of her elderly relative who receives and believes a deluge of AI content on WhatsApp about Sudan’s war feels familiar as well. I see something similar with my own father, who spends far more time on Facebook than I do on Instagram. He is extremely trusting. When he shows me videos of unrealistic products, or oddly behaving pets, his reaction is not suspicion but curiosity. He even asks if we can try some of the items or buy them. The issue is not ignorance, but the growing realism of AI content. AI images were less convincing a few years ago but now, the technology has improved so much, it has become difficult even for younger users to recognize manipulation at first glance. 


        
        <br/> <br/> Malik explains that AI content spreads rapidly through algorithms designed for engagement, not truth. Social media platforms reward sensational or visually appealing material because it generates clicks and shares. My mother’s feed is filled with household gadgets and unrealistic demonstrations precisely because algorithms recognize her willingness to spend small amounts on cute or convenient items. The system capitalizes on that predictability. Over time, this constant exposure makes it difficult to disconnect. What once felt like a harmless mental break becomes something closer to dependency. Malik writes that users are immersed deeper into subjective worlds rather than objective reality. That immersion reshapes how we respond to serious issues. When official accounts publish AI-generated political parodies alongside real news, the line between satire, propaganda, and fact gets blurred. Scrolling starts to feel more like emotional stimulation designed for maximum reactions.
        <br/> <br/>The most disturbing aspect of this change is how it affects human connections. Whether it was exchanging information or just having a casual discussion, the internet used to be a place for real contact. These days, feeds are filled with automated content, AI-generated graphics, and algorithmically boosted interests.  Instead of bringing people closer, this ecosystem risks distancing us from one another and from shared reality. According to Malik, the threat isn't only misinformation, but disorientation. When everything feels curated, exaggerated, or artificially enhanced, urgency fades, and real crises compete with aesthetic distractions and political fantasies in the same endless scroll. The outcome is paralysis rather than ignorance. We don't lack knowledge. Apps constantly overload and nudge us towards content that keeps us scrolling rather than thinking critically. If we are to resist this trend, we must consciously choose critical engagement and genuine human connection over the passive consumption shaped by algorithms.


